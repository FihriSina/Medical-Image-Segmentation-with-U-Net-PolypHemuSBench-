# Medical Image Segmentation with U-Net (PolypHemuSBench)

## ğŸ“‚ Project Contents

- `DeepLearning2.ipynb`: Project source code in Jupyter Notebook
- `Deep Learning 2 Raporu.pdf`: Project report (in Turkish)
- Model training and testing
- Sample visual outputs
- Metric analysis
- Evaluation and suggestions

## ğŸ§  Methods and Architecture

- **Model**: U-Net (Encoderâ€“Decoder based CNN for segmentation)
- **Dataset**: [PolypHemuSBench](https://polyphemus.grand-challenge.org/)
- **Input Size**: 256x256
- **Epochs**: 150
- **Optimizer**: Adam (lr=0.001)
- **Loss Function**: Dice Loss
- **Learning Rate Scheduler**: StepLR (step_size=30, gamma=0.1)

### ğŸ¨ Data Augmentation
To improve generalization and reduce overfitting:

- `RandomHorizontalFlip`
- `RandomVerticalFlip`
- `RandomRotation(30)`
- `RandomAffine`
- `ColorJitter`

## ğŸ“Š Performance Metrics

| Metric     | Test Result |
|------------|-------------|
| F1 Score   | 0.2811      |
| IoU        | 0.1850      |
| Accuracy   | 0.0499      |
| Precision  | 0.0142      |
| Recall     | 0.0377      |

## ğŸ–¼ï¸ Visual Output
Model predictions and ground truth masks are visually compared. Example images are available in the report.

## ğŸ” Evaluation
While the model showed promising F1 and IoU scores on the validation set, it struggled on the test setâ€”particularly with a low precision score, indicating many false positives. This suggests overfitting and class imbalance issues.

## ğŸ’¡ Suggestions for Improvement

- Combine BCE + Dice loss for better class balance and learning
- Try advanced architectures like Attention U-Net
- Expand data augmentation strategies
- Use class-weighted or focal loss to handle class imbalance
- Tune prediction threshold to optimize precision-recall trade-off


---


# U-Net ile Medikal GÃ¶rÃ¼ntÃ¼ Segmentasyonu (PolypHemuSBench)


## ğŸ“‚ Proje Ä°Ã§eriÄŸi

- `DeepLearning2.ipynb`: Projenin Python kodlarÄ± (Jupyter Notebook)
- `Deep Learning 2 Raporu.pdf`: Proje raporu (TÃ¼rkÃ§e)
- EÄŸitim ve test sÃ¼reci
- GÃ¶rsel Ã§Ä±ktÄ± Ã¶rnekleri
- Metrik analizleri
- SonuÃ§ ve Ã¶neriler

## ğŸ§  KullanÄ±lan YÃ¶ntemler ve Mimari

- **Model**: U-Net (Encoder-Decoder yapÄ±lÄ± CNN mimarisi)
- **Veri Seti**: [PolypHemuSBench](https://polyphemus.grand-challenge.org/)
- **GiriÅŸ Boyutu**: 256x256
- **Epoch**: 150
- **Optimizer**: Adam (lr=0.001)
- **KayÄ±p Fonksiyonu**: Dice Loss
- **Ã–ÄŸrenme OranÄ± GÃ¼ncelleyici**: StepLR (step_size=30, gamma=0.1)

### ğŸ¨ Veri ArtÄ±rma (Augmentation)
- `RandomHorizontalFlip`
- `RandomVerticalFlip`
- `RandomRotation(30)`
- `RandomAffine`
- `ColorJitter`

## ğŸ“Š Performans Metrikleri

| Metrik     | Test Sonucu |
|------------|-------------|
| F1 Score   | 0.2811      |
| IoU        | 0.1850      |
| Accuracy   | 0.0499      |
| Precision  | 0.0142      |
| Recall     | 0.0377      |

## ğŸ–¼ï¸ Model Ã‡Ä±ktÄ±sÄ±
Modelin tahmin ettiÄŸi maskeler ve gerÃ§ek maskeler gÃ¶rsel olarak karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Ã–rnek gÃ¶rseller raporda bulunmaktadÄ±r.

## ğŸ” DeÄŸerlendirme
Model doÄŸrulama verisinde yÃ¼ksek F1 ve IoU skorlarÄ±na ulaÅŸmasÄ±na raÄŸmen, test setinde dÃ¼ÅŸÃ¼k precision deÄŸeri nedeniyle fazla sayÄ±da yanlÄ±ÅŸ pozitif tahmin Ã¼retmiÅŸtir. Bu durum overfitting ve sÄ±nÄ±f dengesizliÄŸinden kaynaklanÄ±yor olabilir.

## ğŸ’¡ GeleceÄŸe YÃ¶nelik Ã–neriler

- BCE + Dice kombinasyonu ile daha dengeli kayÄ±p fonksiyonu kullanÄ±mÄ±
- Attention U-Net gibi geliÅŸmiÅŸ mimarilerin test edilmesi
- Daha fazla augmentasyon tekniÄŸi
- Class-weighted veya focal loss kullanÄ±mÄ±
- Tahmin eÅŸik deÄŸerinin ayarlanmasÄ±


---

